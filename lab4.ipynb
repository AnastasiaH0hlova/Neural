{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow 2.x\n",
    "\n",
    "1) Подготовка данных\n",
    "\n",
    "2) Использование Keras Model API\n",
    "\n",
    "3) Использование Keras Sequential + Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/tutorials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для выполнения лабораторной работы необходимо установить tensorflow версии 2.0 или выше .\n",
    "\n",
    "Рекомендуется использовать возможности Colab'а по обучению моделей на GPU.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "device = '/device:gpu:1'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подготовка данных\n",
    "Загрузите набор данных из предыдущей лабораторной работы. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (49000, 32, 32, 3)\n",
      "Train labels shape:  (49000,) int32\n",
      "Validation data shape:  (1000, 32, 32, 3)\n",
      "Validation labels shape:  (1000,)\n",
      "Test data shape:  (10000, 32, 32, 3)\n",
      "Test labels shape:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "def load_cifar10(num_training=49000, num_validation=1000, num_test=10000):\n",
    "    \"\"\"\n",
    "    Fetch the CIFAR-10 dataset from the web and perform preprocessing to prepare\n",
    "    it for the two-layer neural net classifier. These are the same steps as\n",
    "    we used for the SVM, but condensed to a single function.\n",
    "    \"\"\"\n",
    "    # Load the raw CIFAR-10 dataset and use appropriate data types and shapes\n",
    "    cifar10 = tf.keras.datasets.cifar10.load_data()\n",
    "    (X_train, y_train), (X_test, y_test) = cifar10\n",
    "    X_train = np.asarray(X_train, dtype=np.float32)\n",
    "    y_train = np.asarray(y_train, dtype=np.int32).flatten()\n",
    "    X_test = np.asarray(X_test, dtype=np.float32)\n",
    "    y_test = np.asarray(y_test, dtype=np.int32).flatten()\n",
    "\n",
    "    # Subsample the data\n",
    "    mask = range(num_training, num_training + num_validation)\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    mask = range(num_training)\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    mask = range(num_test)\n",
    "    X_test = X_test[mask]\n",
    "    y_test = y_test[mask]\n",
    "\n",
    "    # Normalize the data: subtract the mean pixel and divide by std\n",
    "    mean_pixel = X_train.mean(axis=(0, 1, 2), keepdims=True)\n",
    "    std_pixel = X_train.std(axis=(0, 1, 2), keepdims=True)\n",
    "    X_train = (X_train - mean_pixel) / std_pixel\n",
    "    X_val = (X_val - mean_pixel) / std_pixel\n",
    "    X_test = (X_test - mean_pixel) / std_pixel\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "# If there are errors with SSL downloading involving self-signed certificates,\n",
    "# it may be that your Python version was recently installed on the current machine.\n",
    "# See: https://github.com/tensorflow/tensorflow/issues/10779\n",
    "# To fix, run the command: /Applications/Python\\ 3.7/Install\\ Certificates.command\n",
    "#   ...replacing paths as necessary.\n",
    "\n",
    "# Invoke the above function to get our data.\n",
    "NHW = (0, 1, 2)\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_cifar10()\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape, y_train.dtype)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    def __init__(self, X, y, batch_size, shuffle=False):\n",
    "        \"\"\"\n",
    "        Construct a Dataset object to iterate over data X and labels y\n",
    "        \n",
    "        Inputs:\n",
    "        - X: Numpy array of data, of any shape\n",
    "        - y: Numpy array of labels, of any shape but with y.shape[0] == X.shape[0]\n",
    "        - batch_size: Integer giving number of elements per minibatch\n",
    "        - shuffle: (optional) Boolean, whether to shuffle the data on each epoch\n",
    "        \"\"\"\n",
    "        assert X.shape[0] == y.shape[0], 'Got different numbers of data and labels'\n",
    "        self.X, self.y = X, y\n",
    "        self.batch_size, self.shuffle = batch_size, shuffle\n",
    "\n",
    "    def __iter__(self):\n",
    "        N, B = self.X.shape[0], self.batch_size\n",
    "        idxs = np.arange(N)\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(idxs)\n",
    "        return iter((self.X[i:i+B], self.y[i:i+B]) for i in range(0, N, B))\n",
    "\n",
    "\n",
    "train_dset = Dataset(X_train, y_train, batch_size=64, shuffle=True)\n",
    "val_dset = Dataset(X_val, y_val, batch_size=64, shuffle=False)\n",
    "test_dset = Dataset(X_test, y_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (64, 32, 32, 3) (64,)\n",
      "1 (64, 32, 32, 3) (64,)\n",
      "2 (64, 32, 32, 3) (64,)\n",
      "3 (64, 32, 32, 3) (64,)\n",
      "4 (64, 32, 32, 3) (64,)\n",
      "5 (64, 32, 32, 3) (64,)\n",
      "6 (64, 32, 32, 3) (64,)\n"
     ]
    }
   ],
   "source": [
    "# We can iterate through a dataset like this:\n",
    "for t, (x, y) in enumerate(train_dset):\n",
    "    print(t, x.shape, y.shape)\n",
    "    if t > 5: break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Keras Model Subclassing API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Для реализации собственной модели с помощью Keras Model Subclassing API необходимо выполнить следующие шаги:\n",
    "\n",
    "1) Определить новый класс, который является наследником tf.keras.Model.\n",
    "\n",
    "2) В методе __init__() определить все необходимые слои из модуля tf.keras.layer\n",
    "\n",
    "3) Реализовать прямой проход в методе call() на основе слоев, объявленных в __init__()\n",
    "\n",
    "Ниже приведен пример использования keras API для определения двухслойной полносвязной сети. \n",
    "\n",
    "https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "(64, 10)\n"
     ]
    }
   ],
   "source": [
    "class TwoLayerFC(tf.keras.Model):\n",
    "    def __init__(self, hidden_size, num_classes):\n",
    "        super(TwoLayerFC, self).__init__()        \n",
    "        initializer = tf.initializers.VarianceScaling(scale=2.0,seed=42)\n",
    "        self.fc1 = tf.keras.layers.Dense(hidden_size, activation='relu',\n",
    "                                   kernel_initializer=initializer)\n",
    "        self.fc2 = tf.keras.layers.Dense(num_classes, activation='softmax',\n",
    "                                   kernel_initializer=initializer)\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "    \n",
    "    def call(self, x, training=False):\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def test_TwoLayerFC():\n",
    "    \"\"\" A small unit test to exercise the TwoLayerFC model above. \"\"\"\n",
    "    input_size, hidden_size, num_classes = 50, 42, 10\n",
    "    x = tf.zeros((64, input_size))\n",
    "    model = TwoLayerFC(hidden_size, num_classes)\n",
    "    with tf.device('/device:gpu:0'):\n",
    "        scores = model(x)\n",
    "        print(scores.shape)\n",
    "        \n",
    "test_TwoLayerFC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте трехслойную CNN для вашей задачи классификации. \n",
    "\n",
    "Архитектура сети:\n",
    "    \n",
    "1. Сверточный слой (5 x 5 kernels, zero-padding = 'same')\n",
    "2. Функция активации ReLU \n",
    "3. Сверточный слой (3 x 3 kernels, zero-padding = 'same')\n",
    "4. Функция активации ReLU \n",
    "5. Полносвязный слой \n",
    "6. Функция активации Softmax \n",
    "\n",
    "https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/Conv2D\n",
    "\n",
    "https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThreeLayerConvNet(tf.keras.Model):\n",
    "    def __init__(self, channel_1, channel_2, num_classes):\n",
    "        super(ThreeLayerConvNet, self).__init__()\n",
    "        ########################################################################\n",
    "        # TODO: Implement the __init__ method for a three-layer ConvNet. You   #\n",
    "        # should instantiate layer objects to be used in the forward pass.     #\n",
    "        ########################################################################\n",
    "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "        initializer = tf.initializers.VarianceScaling(scale=2.0,seed=42)\n",
    "        self.conv1 = tf.keras.layers.Conv2D(filters=channel_1,kernel_size=(5,5), activation='relu',padding='same',\n",
    "                                   kernel_initializer=initializer)\n",
    "        self.conv2 = tf.keras.layers.Conv2D(filters=channel_2,kernel_size=(3,3), activation='relu',padding='same',\n",
    "                                   kernel_initializer=initializer)\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.fc3 = tf.keras.layers.Dense(num_classes, activation='softmax',\n",
    "                                   kernel_initializer=initializer)\n",
    "\n",
    "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        ########################################################################\n",
    "        #                           END OF YOUR CODE                           #\n",
    "        ########################################################################\n",
    "        \n",
    "    def call(self, x, training=False):\n",
    "        scores = None\n",
    "        ########################################################################\n",
    "        # TODO: Implement the forward pass for a three-layer ConvNet. You      #\n",
    "        # should use the layer objects defined in the __init__ method.         #\n",
    "        ########################################################################\n",
    "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "\n",
    "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        ########################################################################\n",
    "        #                           END OF YOUR CODE                           #\n",
    "        ########################################################################        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 10)\n"
     ]
    }
   ],
   "source": [
    "def test_ThreeLayerConvNet():    \n",
    "    channel_1, channel_2, num_classes = 12, 8, 10\n",
    "    model = ThreeLayerConvNet(channel_1, channel_2, num_classes)\n",
    "    with tf.device(device):\n",
    "        x = tf.zeros((64, 3, 32, 32))\n",
    "        scores = model(x)\n",
    "        print(scores.shape)\n",
    "\n",
    "test_ThreeLayerConvNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример реализации процесса обучения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_part34(model_init_fn, optimizer_init_fn, num_epochs=1, is_training=False,print_every = 100):\n",
    "    \"\"\"\n",
    "    Simple training loop for use with models defined using tf.keras. It trains\n",
    "    a model for one epoch on the CIFAR-10 training set and periodically checks\n",
    "    accuracy on the CIFAR-10 validation set.\n",
    "    \n",
    "    Inputs:\n",
    "    - model_init_fn: A function that takes no parameters; when called it\n",
    "      constructs the model we want to train: model = model_init_fn()\n",
    "    - optimizer_init_fn: A function which takes no parameters; when called it\n",
    "      constructs the Optimizer object we will use to optimize the model:\n",
    "      optimizer = optimizer_init_fn()\n",
    "    - num_epochs: The number of epochs to train for\n",
    "    \n",
    "    Returns: Nothing, but prints progress during trainingn\n",
    "    \"\"\"    \n",
    "    with tf.device(device):\n",
    "\n",
    "        \n",
    "        loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "        \n",
    "        model = model_init_fn()\n",
    "        optimizer = optimizer_init_fn()\n",
    "        \n",
    "        train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "        train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "    \n",
    "        val_loss = tf.keras.metrics.Mean(name='val_loss')\n",
    "        val_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='val_accuracy')\n",
    "        \n",
    "        t = 0\n",
    "        for epoch in range(num_epochs):\n",
    "            \n",
    "            # Reset the metrics - https://www.tensorflow.org/alpha/guide/migration_guide#new-style_metrics\n",
    "            # train_loss.reset_states()\n",
    "            # train_accuracy.reset_states()\n",
    "            \n",
    "            for x_np, y_np in train_dset:\n",
    "                with tf.GradientTape() as tape:\n",
    "                    \n",
    "                    # Use the model function to build the forward pass.\n",
    "                    scores = model(x_np, training=is_training)\n",
    "                    loss = loss_fn(y_np, scores)\n",
    "      \n",
    "                    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "                    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "                    \n",
    "                    # Update the metrics\n",
    "                    train_loss.update_state(loss)\n",
    "                    train_accuracy.update_state(y_np, scores)\n",
    "                    \n",
    "                    if t % print_every == 0:\n",
    "                        # val_loss.reset_states()\n",
    "                        # val_accuracy.reset_states()\n",
    "                        for test_x, test_y in val_dset:\n",
    "                            # During validation at end of epoch, training set to False\n",
    "                            prediction = model(test_x, training=False)\n",
    "                            t_loss = loss_fn(test_y, prediction)\n",
    "\n",
    "                            val_loss.update_state(t_loss)\n",
    "                            val_accuracy.update_state(test_y, prediction)\n",
    "                        \n",
    "                        template = 'Iteration {}, Epoch {}, Loss: {}, Accuracy: {}, Val Loss: {}, Val Accuracy: {}'\n",
    "                        print (template.format(t, epoch+1,\n",
    "                                             train_loss.result(),\n",
    "                                             train_accuracy.result()*100,\n",
    "                                             val_loss.result(),\n",
    "                                             val_accuracy.result()*100))\n",
    "                    t += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Epoch 1, Loss: 3.0009889602661133, Accuracy: 10.9375, Val Loss: 2.950167417526245, Val Accuracy: 12.700000762939453\n",
      "Iteration 100, Epoch 1, Loss: 2.2542262077331543, Accuracy: 28.434404373168945, Val Loss: 2.4361326694488525, Val Accuracy: 24.75\n",
      "Iteration 200, Epoch 1, Loss: 2.084911823272705, Accuracy: 32.22170639038086, Val Loss: 2.2400596141815186, Val Accuracy: 29.69999885559082\n",
      "Iteration 300, Epoch 1, Loss: 2.0046002864837646, Accuracy: 34.105064392089844, Val Loss: 2.1558661460876465, Val Accuracy: 31.450000762939453\n",
      "Iteration 400, Epoch 1, Loss: 1.9358911514282227, Accuracy: 35.719295501708984, Val Loss: 2.070573091506958, Val Accuracy: 33.5\n",
      "Iteration 500, Epoch 1, Loss: 1.8904615640640259, Accuracy: 36.72343063354492, Val Loss: 2.000894546508789, Val Accuracy: 35.266666412353516\n",
      "Iteration 600, Epoch 1, Loss: 1.8595675230026245, Accuracy: 37.7261848449707, Val Loss: 1.9540117979049683, Val Accuracy: 36.4428596496582\n",
      "Iteration 700, Epoch 1, Loss: 1.8340221643447876, Accuracy: 38.48297119140625, Val Loss: 1.9141288995742798, Val Accuracy: 37.400001525878906\n"
     ]
    }
   ],
   "source": [
    "hidden_size, num_classes = 4000, 10\n",
    "learning_rate = 1e-2\n",
    "\n",
    "def model_init_fn():\n",
    "    return TwoLayerFC(hidden_size, num_classes)\n",
    "\n",
    "def optimizer_init_fn():\n",
    "    return tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "\n",
    "train_part34(model_init_fn, optimizer_init_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите трехслойную CNN. В tf.keras.optimizers.SGD укажите Nesterov momentum = 0.9 . \n",
    "\n",
    "https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/optimizers/SGD\n",
    "\n",
    "Значение accuracy на валидационной выборке после 1 эпохи обучения должно быть > 50% ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Epoch 1, Loss: 3.01434326171875, Accuracy: 20.3125, Val Loss: 5.303304672241211, Val Accuracy: 13.0\n",
      "Iteration 10, Epoch 1, Loss: 3.1446175575256348, Accuracy: 18.323863983154297, Val Loss: 3.7688117027282715, Val Accuracy: 16.69999885559082\n",
      "Iteration 20, Epoch 1, Loss: 2.6898348331451416, Accuracy: 20.684524536132812, Val Loss: 3.2262210845947266, Val Accuracy: 19.133333206176758\n",
      "Iteration 30, Epoch 1, Loss: 2.4940707683563232, Accuracy: 22.782258987426758, Val Loss: 2.926913261413574, Val Accuracy: 21.875\n",
      "Iteration 40, Epoch 1, Loss: 2.36868953704834, Accuracy: 25.22865867614746, Val Loss: 2.7297816276550293, Val Accuracy: 24.1200008392334\n",
      "Iteration 50, Epoch 1, Loss: 2.2780258655548096, Accuracy: 26.13357925415039, Val Loss: 2.5925514698028564, Val Accuracy: 25.433334350585938\n",
      "Iteration 60, Epoch 1, Loss: 2.204115390777588, Accuracy: 27.561477661132812, Val Loss: 2.4865174293518066, Val Accuracy: 26.914287567138672\n",
      "Iteration 70, Epoch 1, Loss: 2.1504828929901123, Accuracy: 28.653167724609375, Val Loss: 2.4016544818878174, Val Accuracy: 28.325000762939453\n",
      "Iteration 80, Epoch 1, Loss: 2.1085002422332764, Accuracy: 29.745370864868164, Val Loss: 2.3330023288726807, Val Accuracy: 29.488887786865234\n",
      "Iteration 90, Epoch 1, Loss: 2.0656373500823975, Accuracy: 30.76923179626465, Val Loss: 2.2759180068969727, Val Accuracy: 30.520000457763672\n",
      "Iteration 100, Epoch 1, Loss: 2.0252020359039307, Accuracy: 31.66769790649414, Val Loss: 2.225973606109619, Val Accuracy: 31.436363220214844\n",
      "Iteration 110, Epoch 1, Loss: 1.9945145845413208, Accuracy: 32.41835403442383, Val Loss: 2.1849441528320312, Val Accuracy: 32.133331298828125\n",
      "Iteration 120, Epoch 1, Loss: 1.9691007137298584, Accuracy: 33.070762634277344, Val Loss: 2.1441571712493896, Val Accuracy: 33.03076934814453\n",
      "Iteration 130, Epoch 1, Loss: 1.944177508354187, Accuracy: 33.695133209228516, Val Loss: 2.1079509258270264, Val Accuracy: 33.89999771118164\n",
      "Iteration 140, Epoch 1, Loss: 1.923715591430664, Accuracy: 34.38608169555664, Val Loss: 2.0762057304382324, Val Accuracy: 34.62666702270508\n",
      "Iteration 150, Epoch 1, Loss: 1.9024900197982788, Accuracy: 35.04759979248047, Val Loss: 2.050004243850708, Val Accuracy: 35.17499923706055\n",
      "Iteration 160, Epoch 1, Loss: 1.8862122297286987, Accuracy: 35.47166442871094, Val Loss: 2.0233521461486816, Val Accuracy: 35.735294342041016\n",
      "Iteration 170, Epoch 1, Loss: 1.870432734489441, Accuracy: 36.019737243652344, Val Loss: 1.9989924430847168, Val Accuracy: 36.255558013916016\n",
      "Iteration 180, Epoch 1, Loss: 1.8534895181655884, Accuracy: 36.464088439941406, Val Loss: 1.9782230854034424, Val Accuracy: 36.7315788269043\n",
      "Iteration 190, Epoch 1, Loss: 1.8387513160705566, Accuracy: 36.9273567199707, Val Loss: 1.9582622051239014, Val Accuracy: 37.22999954223633\n",
      "Iteration 200, Epoch 1, Loss: 1.8292325735092163, Accuracy: 37.103546142578125, Val Loss: 1.939130187034607, Val Accuracy: 37.661903381347656\n",
      "Iteration 210, Epoch 1, Loss: 1.8184345960617065, Accuracy: 37.38151931762695, Val Loss: 1.9239898920059204, Val Accuracy: 37.986366271972656\n",
      "Iteration 220, Epoch 1, Loss: 1.8057522773742676, Accuracy: 37.65554428100586, Val Loss: 1.9083541631698608, Val Accuracy: 38.3739128112793\n",
      "Iteration 230, Epoch 1, Loss: 1.7950186729431152, Accuracy: 37.91260528564453, Val Loss: 1.8923393487930298, Val Accuracy: 38.74583435058594\n",
      "Iteration 240, Epoch 1, Loss: 1.7848044633865356, Accuracy: 38.23262405395508, Val Loss: 1.877837061882019, Val Accuracy: 39.09600067138672\n",
      "Iteration 250, Epoch 1, Loss: 1.7764886617660522, Accuracy: 38.52714157104492, Val Loss: 1.8641867637634277, Val Accuracy: 39.376922607421875\n",
      "Iteration 260, Epoch 1, Loss: 1.765548586845398, Accuracy: 38.87092590332031, Val Loss: 1.85075044631958, Val Accuracy: 39.69629669189453\n",
      "Iteration 270, Epoch 1, Loss: 1.7552975416183472, Accuracy: 39.120155334472656, Val Loss: 1.8380463123321533, Val Accuracy: 40.05714416503906\n",
      "Iteration 280, Epoch 1, Loss: 1.747517466545105, Accuracy: 39.31272506713867, Val Loss: 1.8252776861190796, Val Accuracy: 40.406898498535156\n",
      "Iteration 290, Epoch 1, Loss: 1.7388135194778442, Accuracy: 39.583335876464844, Val Loss: 1.8135759830474854, Val Accuracy: 40.77333068847656\n",
      "Iteration 300, Epoch 1, Loss: 1.7290276288986206, Accuracy: 39.91901779174805, Val Loss: 1.8026463985443115, Val Accuracy: 41.106449127197266\n",
      "Iteration 310, Epoch 1, Loss: 1.7207505702972412, Accuracy: 40.20297622680664, Val Loss: 1.7918848991394043, Val Accuracy: 41.35312271118164\n",
      "Iteration 320, Epoch 1, Loss: 1.7141941785812378, Accuracy: 40.459503173828125, Val Loss: 1.7818483114242554, Val Accuracy: 41.60000228881836\n",
      "Iteration 330, Epoch 1, Loss: 1.7046674489974976, Accuracy: 40.77605438232422, Val Loss: 1.772149920463562, Val Accuracy: 41.838233947753906\n",
      "Iteration 340, Epoch 1, Loss: 1.696393370628357, Accuracy: 41.01906204223633, Val Loss: 1.7637163400650024, Val Accuracy: 42.06856918334961\n",
      "Iteration 350, Epoch 1, Loss: 1.6892199516296387, Accuracy: 41.1680908203125, Val Loss: 1.7551549673080444, Val Accuracy: 42.272220611572266\n",
      "Iteration 360, Epoch 1, Loss: 1.6826701164245605, Accuracy: 41.46900939941406, Val Loss: 1.7461599111557007, Val Accuracy: 42.48918914794922\n",
      "Iteration 370, Epoch 1, Loss: 1.6724932193756104, Accuracy: 41.76633834838867, Val Loss: 1.7389007806777954, Val Accuracy: 42.68157958984375\n",
      "Iteration 380, Epoch 1, Loss: 1.6650372743606567, Accuracy: 42.015254974365234, Val Loss: 1.7303006649017334, Val Accuracy: 42.92564010620117\n",
      "Iteration 390, Epoch 1, Loss: 1.656726598739624, Accuracy: 42.3073844909668, Val Loss: 1.7231159210205078, Val Accuracy: 43.119998931884766\n",
      "Iteration 400, Epoch 1, Loss: 1.6495423316955566, Accuracy: 42.50312042236328, Val Loss: 1.715912938117981, Val Accuracy: 43.273170471191406\n",
      "Iteration 410, Epoch 1, Loss: 1.6428771018981934, Accuracy: 42.696929931640625, Val Loss: 1.708984375, Val Accuracy: 43.42380905151367\n",
      "Iteration 420, Epoch 1, Loss: 1.63707435131073, Accuracy: 42.855552673339844, Val Loss: 1.7019069194793701, Val Accuracy: 43.599998474121094\n",
      "Iteration 430, Epoch 1, Loss: 1.6308239698410034, Accuracy: 43.03219223022461, Val Loss: 1.6960647106170654, Val Accuracy: 43.75227355957031\n",
      "Iteration 440, Epoch 1, Loss: 1.6255775690078735, Accuracy: 43.19728088378906, Val Loss: 1.6894694566726685, Val Accuracy: 43.913333892822266\n",
      "Iteration 450, Epoch 1, Loss: 1.620652437210083, Accuracy: 43.37236404418945, Val Loss: 1.6836292743682861, Val Accuracy: 44.010868072509766\n",
      "Iteration 460, Epoch 1, Loss: 1.6148146390914917, Accuracy: 43.53985595703125, Val Loss: 1.6772873401641846, Val Accuracy: 44.180850982666016\n",
      "Iteration 470, Epoch 1, Loss: 1.6085246801376343, Accuracy: 43.75663375854492, Val Loss: 1.6725621223449707, Val Accuracy: 44.272918701171875\n",
      "Iteration 480, Epoch 1, Loss: 1.603395938873291, Accuracy: 43.915672302246094, Val Loss: 1.6672232151031494, Val Accuracy: 44.3775520324707\n",
      "Iteration 490, Epoch 1, Loss: 1.5984256267547607, Accuracy: 44.115962982177734, Val Loss: 1.6614956855773926, Val Accuracy: 44.512001037597656\n",
      "Iteration 500, Epoch 1, Loss: 1.5940191745758057, Accuracy: 44.28642654418945, Val Loss: 1.6561108827590942, Val Accuracy: 44.61372375488281\n",
      "Iteration 510, Epoch 1, Loss: 1.5904871225357056, Accuracy: 44.42270278930664, Val Loss: 1.6510740518569946, Val Accuracy: 44.728843688964844\n",
      "Iteration 520, Epoch 1, Loss: 1.5875563621520996, Accuracy: 44.49076461791992, Val Loss: 1.6460169553756714, Val Accuracy: 44.883018493652344\n",
      "Iteration 530, Epoch 1, Loss: 1.5847885608673096, Accuracy: 44.5621452331543, Val Loss: 1.641035556793213, Val Accuracy: 45.03888702392578\n",
      "Iteration 540, Epoch 1, Loss: 1.5803016424179077, Accuracy: 44.760860443115234, Val Loss: 1.6358801126480103, Val Accuracy: 45.185455322265625\n",
      "Iteration 550, Epoch 1, Loss: 1.5766421556472778, Accuracy: 44.86445236206055, Val Loss: 1.6311689615249634, Val Accuracy: 45.3071403503418\n",
      "Iteration 560, Epoch 1, Loss: 1.5727382898330688, Accuracy: 44.97270584106445, Val Loss: 1.6265369653701782, Val Accuracy: 45.42982482910156\n",
      "Iteration 570, Epoch 1, Loss: 1.5685093402862549, Accuracy: 45.12642288208008, Val Loss: 1.621734857559204, Val Accuracy: 45.56034469604492\n",
      "Iteration 580, Epoch 1, Loss: 1.564697265625, Accuracy: 45.229129791259766, Val Loss: 1.617063283920288, Val Accuracy: 45.6898307800293\n",
      "Iteration 590, Epoch 1, Loss: 1.5612257719039917, Accuracy: 45.33629608154297, Val Loss: 1.612741231918335, Val Accuracy: 45.80666732788086\n",
      "Iteration 600, Epoch 1, Loss: 1.5583006143569946, Accuracy: 45.41389465332031, Val Loss: 1.6082592010498047, Val Accuracy: 45.92458724975586\n",
      "Iteration 610, Epoch 1, Loss: 1.553606629371643, Accuracy: 45.573341369628906, Val Loss: 1.6038048267364502, Val Accuracy: 46.053226470947266\n",
      "Iteration 620, Epoch 1, Loss: 1.5504138469696045, Accuracy: 45.70249557495117, Val Loss: 1.5998785495758057, Val Accuracy: 46.155555725097656\n",
      "Iteration 630, Epoch 1, Loss: 1.546936273574829, Accuracy: 45.8151741027832, Val Loss: 1.5956770181655884, Val Accuracy: 46.2734375\n",
      "Iteration 640, Epoch 1, Loss: 1.5439832210540771, Accuracy: 45.914588928222656, Val Loss: 1.5918123722076416, Val Accuracy: 46.38615417480469\n",
      "Iteration 650, Epoch 1, Loss: 1.5411205291748047, Accuracy: 45.996543884277344, Val Loss: 1.5879573822021484, Val Accuracy: 46.47878646850586\n",
      "Iteration 660, Epoch 1, Loss: 1.5376800298690796, Accuracy: 46.116207122802734, Val Loss: 1.584023118019104, Val Accuracy: 46.57313537597656\n",
      "Iteration 670, Epoch 1, Loss: 1.5345172882080078, Accuracy: 46.22066116333008, Val Loss: 1.5807219743728638, Val Accuracy: 46.65882110595703\n",
      "Iteration 680, Epoch 1, Loss: 1.5320931673049927, Accuracy: 46.28074645996094, Val Loss: 1.5772243738174438, Val Accuracy: 46.775360107421875\n",
      "Iteration 690, Epoch 1, Loss: 1.5290559530258179, Accuracy: 46.404666900634766, Val Loss: 1.5737042427062988, Val Accuracy: 46.88428497314453\n",
      "Iteration 700, Epoch 1, Loss: 1.5267598628997803, Accuracy: 46.49607849121094, Val Loss: 1.5708215236663818, Val Accuracy: 46.93661880493164\n",
      "Iteration 710, Epoch 1, Loss: 1.5230767726898193, Accuracy: 46.60908889770508, Val Loss: 1.5670291185379028, Val Accuracy: 47.05833053588867\n",
      "Iteration 720, Epoch 1, Loss: 1.5189590454101562, Accuracy: 46.77314376831055, Val Loss: 1.5638165473937988, Val Accuracy: 47.15342712402344\n",
      "Iteration 730, Epoch 1, Loss: 1.5163594484329224, Accuracy: 46.8536262512207, Val Loss: 1.5606420040130615, Val Accuracy: 47.26081085205078\n",
      "Iteration 740, Epoch 1, Loss: 1.5129450559616089, Accuracy: 47.00362777709961, Val Loss: 1.5570021867752075, Val Accuracy: 47.35866928100586\n",
      "Iteration 750, Epoch 1, Loss: 1.5107096433639526, Accuracy: 47.0643310546875, Val Loss: 1.5539777278900146, Val Accuracy: 47.45131301879883\n",
      "Iteration 760, Epoch 1, Loss: 1.5075520277023315, Accuracy: 47.18708801269531, Val Loss: 1.5504869222640991, Val Accuracy: 47.57143020629883\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 3e-3\n",
    "channel_1, channel_2, num_classes = 32, 16, 10\n",
    "\n",
    "def model_init_fn():\n",
    "    model = None\n",
    "    ############################################################################\n",
    "    # TODO: Complete the implementation of model_fn.                           #\n",
    "    ############################################################################\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "    model = ThreeLayerConvNet(channel_1,channel_2,num_classes)\n",
    "\n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    ############################################################################\n",
    "    #                           END OF YOUR CODE                               #\n",
    "    ############################################################################\n",
    "    return model\n",
    "\n",
    "def optimizer_init_fn():\n",
    "    optimizer = None\n",
    "    ############################################################################\n",
    "    # TODO: Complete the implementation of model_fn.                           #\n",
    "    ############################################################################\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate,nesterov=True, momentum=0.9)\n",
    "\n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    ############################################################################\n",
    "    #                           END OF YOUR CODE                               #\n",
    "    ############################################################################\n",
    "    return optimizer\n",
    "\n",
    "train_part34(model_init_fn, optimizer_init_fn,print_every=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Использование Keras Sequential API для реализации последовательных моделей.\n",
    "\n",
    "Пример для полносвязной сети:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Epoch 1, Loss: 3.0009889602661133, Accuracy: 10.9375, Val Loss: 2.950167417526245, Val Accuracy: 12.700000762939453\n",
      "Iteration 100, Epoch 1, Loss: 2.2542262077331543, Accuracy: 28.434404373168945, Val Loss: 2.4361326694488525, Val Accuracy: 24.75\n",
      "Iteration 200, Epoch 1, Loss: 2.084911823272705, Accuracy: 32.22170639038086, Val Loss: 2.2400596141815186, Val Accuracy: 29.69999885559082\n",
      "Iteration 300, Epoch 1, Loss: 2.0046002864837646, Accuracy: 34.105064392089844, Val Loss: 2.1558661460876465, Val Accuracy: 31.450000762939453\n",
      "Iteration 400, Epoch 1, Loss: 1.9358911514282227, Accuracy: 35.719295501708984, Val Loss: 2.070573091506958, Val Accuracy: 33.5\n",
      "Iteration 500, Epoch 1, Loss: 1.8904615640640259, Accuracy: 36.72343063354492, Val Loss: 2.000894546508789, Val Accuracy: 35.266666412353516\n",
      "Iteration 600, Epoch 1, Loss: 1.8595675230026245, Accuracy: 37.7261848449707, Val Loss: 1.9540117979049683, Val Accuracy: 36.4428596496582\n",
      "Iteration 700, Epoch 1, Loss: 1.8340221643447876, Accuracy: 38.48297119140625, Val Loss: 1.9141288995742798, Val Accuracy: 37.400001525878906\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-2\n",
    "\n",
    "def model_init_fn():\n",
    "    input_shape = (32, 32, 3)\n",
    "    hidden_layer_size, num_classes = 4000, 10\n",
    "    initializer = tf.initializers.VarianceScaling(scale=2.0,seed=42)\n",
    "    layers = [\n",
    "        tf.keras.layers.Flatten(input_shape=input_shape),\n",
    "        tf.keras.layers.Dense(hidden_layer_size, activation='relu',\n",
    "                              kernel_initializer=initializer),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax', \n",
    "                              kernel_initializer=initializer),\n",
    "    ]\n",
    "    model = tf.keras.Sequential(layers)\n",
    "    return model\n",
    "\n",
    "def optimizer_init_fn():\n",
    "    return tf.keras.optimizers.SGD(learning_rate=learning_rate) \n",
    "\n",
    "train_part34(model_init_fn, optimizer_init_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Альтернативный менее гибкий способ обучения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "766/766 [==============================] - 22s 28ms/step - loss: 1.8287 - sparse_categorical_accuracy: 0.3889 - val_loss: 1.6070 - val_sparse_categorical_accuracy: 0.4550\n",
      "313/313 [==============================] - 1s 5ms/step - loss: 1.6186 - sparse_categorical_accuracy: 0.4448\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.6186422109603882, 0.4447999894618988]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model_init_fn()\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=[tf.keras.metrics.sparse_categorical_accuracy])\n",
    "model.fit(X_train, y_train, batch_size=64, epochs=1, validation_data=(X_val, y_val))\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перепишите реализацию трехслойной CNN с помощью tf.keras.Sequential API . Обучите модель двумя способами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Epoch 1, Loss: 3.01434326171875, Accuracy: 20.3125, Val Loss: 2.7612833976745605, Val Accuracy: 10.40000057220459\n",
      "Iteration 100, Epoch 1, Loss: 2.034350633621216, Accuracy: 28.96039581298828, Val Loss: 2.2920219898223877, Val Accuracy: 23.450000762939453\n",
      "Iteration 200, Epoch 1, Loss: 1.898222804069519, Accuracy: 33.861942291259766, Val Loss: 2.092512369155884, Val Accuracy: 29.766666412353516\n",
      "Iteration 300, Epoch 1, Loss: 1.8226604461669922, Accuracy: 36.290489196777344, Val Loss: 1.9790370464324951, Val Accuracy: 33.64999771118164\n",
      "Iteration 400, Epoch 1, Loss: 1.758641242980957, Accuracy: 38.524784088134766, Val Loss: 1.894837737083435, Val Accuracy: 36.5\n",
      "Iteration 500, Epoch 1, Loss: 1.7105251550674438, Accuracy: 40.094810485839844, Val Loss: 1.835629940032959, Val Accuracy: 38.21666717529297\n",
      "Iteration 600, Epoch 1, Loss: 1.679160714149475, Accuracy: 41.11896896362305, Val Loss: 1.7863787412643433, Val Accuracy: 39.75714111328125\n",
      "Iteration 700, Epoch 1, Loss: 1.6502171754837036, Accuracy: 42.13846206665039, Val Loss: 1.74399995803833, Val Accuracy: 41.150001525878906\n"
     ]
    }
   ],
   "source": [
    "def model_init_fn():\n",
    "    model = None\n",
    "    ############################################################################\n",
    "    # TODO: Construct a three-layer ConvNet using tf.keras.Sequential.         #\n",
    "    ############################################################################\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    input_shape = (32, 32, 3)\n",
    "    channel_1, channel_2, num_classes = 32, 16, 10\n",
    "    initializer = tf.initializers.VarianceScaling(scale=2.0,seed=42)\n",
    "    layers = [\n",
    "        tf.keras.layers.Conv2D(filters=channel_1,kernel_size=(5,5),input_shape = input_shape, activation='relu',padding='same',\n",
    "                                   kernel_initializer=initializer),\n",
    "        tf.keras.layers.Conv2D(filters=channel_2,kernel_size=(3,3), activation='relu',padding='same',\n",
    "                                   kernel_initializer=initializer),                           \n",
    "        tf.keras.layers.Flatten(input_shape=input_shape),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax', \n",
    "                              kernel_initializer=initializer),\n",
    "    ]\n",
    "    model = tf.keras.Sequential(layers)\n",
    "    return model\n",
    "\n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    ############################################################################\n",
    "    #                            END OF YOUR CODE                              #\n",
    "    ############################################################################\n",
    "    return model\n",
    "\n",
    "learning_rate = 5e-4\n",
    "def optimizer_init_fn():\n",
    "    optimizer = None\n",
    "    ############################################################################\n",
    "    # TODO: Complete the implementation of model_fn.                           #\n",
    "    ############################################################################\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate,nesterov=True, momentum=0.9)\n",
    "\n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    ############################################################################\n",
    "    #                           END OF YOUR CODE                               #\n",
    "    ############################################################################\n",
    "    return optimizer\n",
    "\n",
    "train_part34(model_init_fn, optimizer_init_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "766/766 [==============================] - 9s 11ms/step - loss: 1.5908 - sparse_categorical_accuracy: 0.4453 - val_loss: 1.3089 - val_sparse_categorical_accuracy: 0.5330\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.3303 - sparse_categorical_accuracy: 0.5278\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3303310871124268, 0.5278000235557556]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model_init_fn()\n",
    "model.compile(optimizer='sgd',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=[tf.keras.metrics.sparse_categorical_accuracy])\n",
    "model.fit(X_train, y_train, batch_size=64, epochs=1, validation_data=(X_val, y_val))\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Использование Keras Functional API\n",
    "\n",
    "Для реализации более сложных архитектур сети с несколькими входами/выходами, повторным использованием слоев, \"остаточными\" связями (residual connections) необходимо явно указать входные и выходные тензоры. \n",
    "\n",
    "Ниже представлен пример для полносвязной сети. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\initializers\\initializers.py:120: UserWarning: The initializer VarianceScaling is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def two_layer_fc_functional(input_shape, hidden_size, num_classes):  \n",
    "    initializer = tf.initializers.VarianceScaling(scale=2.0)\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    flattened_inputs = tf.keras.layers.Flatten()(inputs)\n",
    "    fc1_output = tf.keras.layers.Dense(hidden_size, activation='relu',\n",
    "                                 kernel_initializer=initializer)(flattened_inputs)\n",
    "    scores = tf.keras.layers.Dense(num_classes, activation='softmax',\n",
    "                             kernel_initializer=initializer)(fc1_output)\n",
    "\n",
    "    # Instantiate the model given inputs and outputs.\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=scores)\n",
    "    return model\n",
    "\n",
    "def test_two_layer_fc_functional():\n",
    "    \"\"\" A small unit test to exercise the TwoLayerFC model above. \"\"\"\n",
    "    input_size, hidden_size, num_classes = 50, 42, 10\n",
    "    input_shape = (50,)\n",
    "    \n",
    "    x = tf.zeros((64, input_size))\n",
    "    model = two_layer_fc_functional(input_shape, hidden_size, num_classes)\n",
    "    \n",
    "    with tf.device(device):\n",
    "        scores = model(x)\n",
    "        print(scores.shape)\n",
    "        \n",
    "test_two_layer_fc_functional()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Epoch 1, Loss: 2.978738784790039, Accuracy: 14.0625, Val Loss: 2.9669694900512695, Val Accuracy: 13.300000190734863\n",
      "Iteration 100, Epoch 1, Loss: 2.23779559135437, Accuracy: 28.310644149780273, Val Loss: 2.4211292266845703, Val Accuracy: 25.850000381469727\n",
      "Iteration 200, Epoch 1, Loss: 2.078127861022949, Accuracy: 32.042911529541016, Val Loss: 2.2087674140930176, Val Accuracy: 31.066667556762695\n",
      "Iteration 300, Epoch 1, Loss: 2.0008347034454346, Accuracy: 33.99086380004883, Val Loss: 2.1269962787628174, Val Accuracy: 32.724998474121094\n",
      "Iteration 400, Epoch 1, Loss: 1.932368516921997, Accuracy: 35.86346435546875, Val Loss: 2.039808511734009, Val Accuracy: 34.70000076293945\n",
      "Iteration 500, Epoch 1, Loss: 1.8899412155151367, Accuracy: 36.88560485839844, Val Loss: 1.9704796075820923, Val Accuracy: 36.19999694824219\n",
      "Iteration 600, Epoch 1, Loss: 1.8589473962783813, Accuracy: 37.87177658081055, Val Loss: 1.9279638528823853, Val Accuracy: 37.099998474121094\n",
      "Iteration 700, Epoch 1, Loss: 1.8318198919296265, Accuracy: 38.523094177246094, Val Loss: 1.889131784439087, Val Accuracy: 38.04999923706055\n"
     ]
    }
   ],
   "source": [
    "input_shape = (32, 32, 3)\n",
    "hidden_size, num_classes = 4000, 10\n",
    "learning_rate = 1e-2\n",
    "\n",
    "def model_init_fn():\n",
    "    return two_layer_fc_functional(input_shape, hidden_size, num_classes)\n",
    "\n",
    "def optimizer_init_fn():\n",
    "    return tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "\n",
    "train_part34(model_init_fn, optimizer_init_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поэкспериментируйте с архитектурой сверточной сети. Для вашего набора данных вам необходимо получить как минимум 70% accuracy на валидационной выборке за 10 эпох обучения. Опишите все эксперименты и сделайте выводы (без выполнения данного пункта работы приниматься не будут). \n",
    "\n",
    "Эспериментируйте с архитектурой, гиперпараметрами, функцией потерь, регуляризацией, методом оптимизации.  \n",
    "\n",
    "https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/BatchNormalization#methods https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/Dropout#methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Iteration 0, Epoch 1, Loss: 3.919969320297241, Accuracy: 3.125, Val Loss: 3.8596322536468506, Val Accuracy: 9.199999809265137\n",
      "Iteration 100, Epoch 1, Loss: 2.1908926963806152, Accuracy: 18.146657943725586, Val Loss: 2.8553974628448486, Val Accuracy: 22.0\n",
      "Iteration 200, Epoch 1, Loss: 2.031324625015259, Accuracy: 24.284826278686523, Val Loss: 2.4507217407226562, Val Accuracy: 29.66666603088379\n",
      "Iteration 300, Epoch 1, Loss: 1.9261105060577393, Accuracy: 28.41569709777832, Val Loss: 2.2191402912139893, Val Accuracy: 33.599998474121094\n",
      "Iteration 400, Epoch 1, Loss: 1.8421093225479126, Accuracy: 31.347412109375, Val Loss: 2.057762622833252, Val Accuracy: 36.86000061035156\n",
      "Iteration 500, Epoch 1, Loss: 1.7816765308380127, Accuracy: 33.748130798339844, Val Loss: 1.944625973701477, Val Accuracy: 38.86666488647461\n",
      "Iteration 600, Epoch 1, Loss: 1.738095998764038, Accuracy: 35.50852966308594, Val Loss: 1.852615475654602, Val Accuracy: 41.228572845458984\n",
      "Iteration 700, Epoch 1, Loss: 1.7011035680770874, Accuracy: 36.996253967285156, Val Loss: 1.7826669216156006, Val Accuracy: 42.974998474121094\n",
      "Iteration 800, Epoch 2, Loss: 1.6669921875, Accuracy: 38.386024475097656, Val Loss: 1.723719835281372, Val Accuracy: 44.70000076293945\n",
      "Iteration 900, Epoch 2, Loss: 1.6374282836914062, Accuracy: 39.517696380615234, Val Loss: 1.6733572483062744, Val Accuracy: 45.97999954223633\n",
      "Iteration 1000, Epoch 2, Loss: 1.611344814300537, Accuracy: 40.51374053955078, Val Loss: 1.629672884941101, Val Accuracy: 47.16363525390625\n",
      "Iteration 1100, Epoch 2, Loss: 1.588337779045105, Accuracy: 41.443782806396484, Val Loss: 1.5920114517211914, Val Accuracy: 48.11666488647461\n",
      "Iteration 1200, Epoch 2, Loss: 1.5647982358932495, Accuracy: 42.38417434692383, Val Loss: 1.5586789846420288, Val Accuracy: 49.161537170410156\n",
      "Iteration 1300, Epoch 2, Loss: 1.5447639226913452, Accuracy: 43.18236541748047, Val Loss: 1.5289562940597534, Val Accuracy: 49.95714569091797\n",
      "Iteration 1400, Epoch 2, Loss: 1.5268033742904663, Accuracy: 43.87104034423828, Val Loss: 1.5025944709777832, Val Accuracy: 50.606666564941406\n",
      "Iteration 1500, Epoch 2, Loss: 1.5094040632247925, Accuracy: 44.57101058959961, Val Loss: 1.4832028150558472, Val Accuracy: 51.20000076293945\n",
      "Iteration 1600, Epoch 3, Loss: 1.4933534860610962, Accuracy: 45.175559997558594, Val Loss: 1.4630974531173706, Val Accuracy: 51.688236236572266\n",
      "Iteration 1700, Epoch 3, Loss: 1.4794092178344727, Accuracy: 45.675270080566406, Val Loss: 1.4426281452178955, Val Accuracy: 52.25555419921875\n",
      "Iteration 1800, Epoch 3, Loss: 1.4660168886184692, Accuracy: 46.16459655761719, Val Loss: 1.4232949018478394, Val Accuracy: 52.7684211730957\n",
      "Iteration 1900, Epoch 3, Loss: 1.452901840209961, Accuracy: 46.651756286621094, Val Loss: 1.4057973623275757, Val Accuracy: 53.34000015258789\n",
      "Iteration 2000, Epoch 3, Loss: 1.4396058320999146, Accuracy: 47.1448860168457, Val Loss: 1.3897532224655151, Val Accuracy: 53.78095626831055\n",
      "Iteration 2100, Epoch 3, Loss: 1.4288325309753418, Accuracy: 47.57841110229492, Val Loss: 1.374651312828064, Val Accuracy: 54.236366271972656\n",
      "Iteration 2200, Epoch 3, Loss: 1.4182360172271729, Accuracy: 47.96614074707031, Val Loss: 1.3597822189331055, Val Accuracy: 54.630435943603516\n",
      "Iteration 2300, Epoch 4, Loss: 1.4075790643692017, Accuracy: 48.35996627807617, Val Loss: 1.3465934991836548, Val Accuracy: 55.099998474121094\n",
      "Iteration 2400, Epoch 4, Loss: 1.3965295553207397, Accuracy: 48.78053665161133, Val Loss: 1.333472490310669, Val Accuracy: 55.47999572753906\n",
      "Iteration 2500, Epoch 4, Loss: 1.3864927291870117, Accuracy: 49.16808319091797, Val Loss: 1.3207802772521973, Val Accuracy: 55.900001525878906\n",
      "Iteration 2600, Epoch 4, Loss: 1.3770588636398315, Accuracy: 49.52882385253906, Val Loss: 1.3090476989746094, Val Accuracy: 56.222225189208984\n",
      "Iteration 2700, Epoch 4, Loss: 1.3675742149353027, Accuracy: 49.89293670654297, Val Loss: 1.2976773977279663, Val Accuracy: 56.55714416503906\n",
      "Iteration 2800, Epoch 4, Loss: 1.3579398393630981, Accuracy: 50.21820068359375, Val Loss: 1.28803551197052, Val Accuracy: 56.82758712768555\n",
      "Iteration 2900, Epoch 4, Loss: 1.3503146171569824, Accuracy: 50.5350456237793, Val Loss: 1.2779181003570557, Val Accuracy: 57.14332962036133\n",
      "Iteration 3000, Epoch 4, Loss: 1.342405080795288, Accuracy: 50.8625373840332, Val Loss: 1.2688897848129272, Val Accuracy: 57.42903518676758\n",
      "Iteration 3100, Epoch 5, Loss: 1.3337825536727905, Accuracy: 51.21038055419922, Val Loss: 1.26010262966156, Val Accuracy: 57.71562576293945\n",
      "Iteration 3200, Epoch 5, Loss: 1.325791597366333, Accuracy: 51.52465057373047, Val Loss: 1.2511935234069824, Val Accuracy: 57.990909576416016\n",
      "Iteration 3300, Epoch 5, Loss: 1.3188501596450806, Accuracy: 51.76210403442383, Val Loss: 1.2431303262710571, Val Accuracy: 58.2529411315918\n",
      "Iteration 3400, Epoch 5, Loss: 1.3117468357086182, Accuracy: 52.019596099853516, Val Loss: 1.234976053237915, Val Accuracy: 58.505714416503906\n",
      "Iteration 3500, Epoch 5, Loss: 1.3048245906829834, Accuracy: 52.29452133178711, Val Loss: 1.227442979812622, Val Accuracy: 58.749996185302734\n",
      "Iteration 3600, Epoch 5, Loss: 1.2978346347808838, Accuracy: 52.56632995605469, Val Loss: 1.2198271751403809, Val Accuracy: 59.01351547241211\n",
      "Iteration 3700, Epoch 5, Loss: 1.2916977405548096, Accuracy: 52.80443572998047, Val Loss: 1.2132487297058105, Val Accuracy: 59.18421173095703\n",
      "Iteration 3800, Epoch 5, Loss: 1.2852253913879395, Accuracy: 53.02794647216797, Val Loss: 1.20705246925354, Val Accuracy: 59.382049560546875\n",
      "Iteration 3900, Epoch 6, Loss: 1.2786732912063599, Accuracy: 53.2775764465332, Val Loss: 1.2006762027740479, Val Accuracy: 59.595001220703125\n",
      "Iteration 4000, Epoch 6, Loss: 1.2722808122634888, Accuracy: 53.50115966796875, Val Loss: 1.1943769454956055, Val Accuracy: 59.819515228271484\n",
      "Iteration 4100, Epoch 6, Loss: 1.2658716440200806, Accuracy: 53.746604919433594, Val Loss: 1.187949299812317, Val Accuracy: 60.0142822265625\n",
      "Iteration 4200, Epoch 6, Loss: 1.2599799633026123, Accuracy: 53.988182067871094, Val Loss: 1.1818305253982544, Val Accuracy: 60.20232391357422\n",
      "Iteration 4300, Epoch 6, Loss: 1.2536931037902832, Accuracy: 54.236690521240234, Val Loss: 1.176218867301941, Val Accuracy: 60.41363525390625\n",
      "Iteration 4400, Epoch 6, Loss: 1.2484185695648193, Accuracy: 54.43767166137695, Val Loss: 1.1709959506988525, Val Accuracy: 60.55111312866211\n",
      "Iteration 4500, Epoch 6, Loss: 1.2428503036499023, Accuracy: 54.655067443847656, Val Loss: 1.1659988164901733, Val Accuracy: 60.72825622558594\n",
      "Iteration 4600, Epoch 7, Loss: 1.2370550632476807, Accuracy: 54.88176345825195, Val Loss: 1.1608879566192627, Val Accuracy: 60.895748138427734\n",
      "Iteration 4700, Epoch 7, Loss: 1.2311203479766846, Accuracy: 55.093109130859375, Val Loss: 1.1554204225540161, Val Accuracy: 61.08124923706055\n",
      "Iteration 4800, Epoch 7, Loss: 1.2255816459655762, Accuracy: 55.30183792114258, Val Loss: 1.150206208229065, Val Accuracy: 61.242855072021484\n",
      "Iteration 4900, Epoch 7, Loss: 1.2203315496444702, Accuracy: 55.50714874267578, Val Loss: 1.145393967628479, Val Accuracy: 61.38999938964844\n",
      "Iteration 5000, Epoch 7, Loss: 1.2148884534835815, Accuracy: 55.72736740112305, Val Loss: 1.1400442123413086, Val Accuracy: 61.57646942138672\n",
      "Iteration 5100, Epoch 7, Loss: 1.2094638347625732, Accuracy: 55.93405532836914, Val Loss: 1.1357003450393677, Val Accuracy: 61.717308044433594\n",
      "Iteration 5200, Epoch 7, Loss: 1.2048391103744507, Accuracy: 56.113548278808594, Val Loss: 1.131385326385498, Val Accuracy: 61.867923736572266\n",
      "Iteration 5300, Epoch 7, Loss: 1.199817419052124, Accuracy: 56.29335021972656, Val Loss: 1.1271164417266846, Val Accuracy: 62.003700256347656\n",
      "Iteration 5400, Epoch 8, Loss: 1.1943162679672241, Accuracy: 56.51063919067383, Val Loss: 1.1230159997940063, Val Accuracy: 62.14908981323242\n",
      "Iteration 5500, Epoch 8, Loss: 1.1888900995254517, Accuracy: 56.70936584472656, Val Loss: 1.1189583539962769, Val Accuracy: 62.278568267822266\n",
      "Iteration 5600, Epoch 8, Loss: 1.184163212776184, Accuracy: 56.88536834716797, Val Loss: 1.1147005558013916, Val Accuracy: 62.41929626464844\n",
      "Iteration 5700, Epoch 8, Loss: 1.1792891025543213, Accuracy: 57.09385299682617, Val Loss: 1.11094331741333, Val Accuracy: 62.55000305175781\n",
      "Iteration 5800, Epoch 8, Loss: 1.1739897727966309, Accuracy: 57.302696228027344, Val Loss: 1.1071414947509766, Val Accuracy: 62.70338821411133\n",
      "Iteration 5900, Epoch 8, Loss: 1.16929030418396, Accuracy: 57.48564147949219, Val Loss: 1.1032010316848755, Val Accuracy: 62.8216667175293\n",
      "Iteration 6000, Epoch 8, Loss: 1.1647297143936157, Accuracy: 57.667701721191406, Val Loss: 1.0994755029678345, Val Accuracy: 62.95082092285156\n",
      "Iteration 6100, Epoch 8, Loss: 1.160056710243225, Accuracy: 57.844818115234375, Val Loss: 1.095544695854187, Val Accuracy: 63.08548355102539\n",
      "Iteration 6200, Epoch 9, Loss: 1.155035138130188, Accuracy: 58.04518508911133, Val Loss: 1.0923863649368286, Val Accuracy: 63.20952224731445\n",
      "Iteration 6300, Epoch 9, Loss: 1.1505520343780518, Accuracy: 58.216148376464844, Val Loss: 1.0888254642486572, Val Accuracy: 63.34218978881836\n",
      "Iteration 6400, Epoch 9, Loss: 1.1461637020111084, Accuracy: 58.381526947021484, Val Loss: 1.0851860046386719, Val Accuracy: 63.45846176147461\n",
      "Iteration 6500, Epoch 9, Loss: 1.1420176029205322, Accuracy: 58.543975830078125, Val Loss: 1.0819916725158691, Val Accuracy: 63.568180084228516\n",
      "Iteration 6600, Epoch 9, Loss: 1.1375070810317993, Accuracy: 58.70766067504883, Val Loss: 1.0787019729614258, Val Accuracy: 63.66865539550781\n",
      "Iteration 6700, Epoch 9, Loss: 1.1336406469345093, Accuracy: 58.85548400878906, Val Loss: 1.07550847530365, Val Accuracy: 63.760292053222656\n",
      "Iteration 6800, Epoch 9, Loss: 1.1295926570892334, Accuracy: 59.01046371459961, Val Loss: 1.0724328756332397, Val Accuracy: 63.87390899658203\n",
      "Iteration 6900, Epoch 10, Loss: 1.125066876411438, Accuracy: 59.17979049682617, Val Loss: 1.0691791772842407, Val Accuracy: 64.00286102294922\n",
      "Iteration 7000, Epoch 10, Loss: 1.1206841468811035, Accuracy: 59.34625244140625, Val Loss: 1.0661648511886597, Val Accuracy: 64.12394714355469\n",
      "Iteration 7100, Epoch 10, Loss: 1.1164238452911377, Accuracy: 59.51572799682617, Val Loss: 1.0632238388061523, Val Accuracy: 64.23332977294922\n",
      "Iteration 7200, Epoch 10, Loss: 1.1127495765686035, Accuracy: 59.656829833984375, Val Loss: 1.0605368614196777, Val Accuracy: 64.32876586914062\n",
      "Iteration 7300, Epoch 10, Loss: 1.1089096069335938, Accuracy: 59.80177688598633, Val Loss: 1.057578206062317, Val Accuracy: 64.4581069946289\n",
      "Iteration 7400, Epoch 10, Loss: 1.1047348976135254, Accuracy: 59.958858489990234, Val Loss: 1.0548272132873535, Val Accuracy: 64.55867004394531\n",
      "Iteration 7500, Epoch 10, Loss: 1.1011797189712524, Accuracy: 60.09215545654297, Val Loss: 1.0521796941757202, Val Accuracy: 64.66316223144531\n",
      "Iteration 7600, Epoch 10, Loss: 1.0974258184432983, Accuracy: 60.23242950439453, Val Loss: 1.049267292022705, Val Accuracy: 64.77013397216797\n"
     ]
    }
   ],
   "source": [
    "class CustomConvNet(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(CustomConvNet, self).__init__()\n",
    "        ############################################################################\n",
    "        # TODO: Construct a model that performs well on CIFAR-10                   #\n",
    "        ############################################################################\n",
    "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "        channel_1, channel_2, num_classes_relu, num_classes_softmax = 32, 64, 100, 10\n",
    "        initializer = tf.initializers.VarianceScaling(scale=2.0)\n",
    "\n",
    "        # Сверточный слой 1: 32 фильтра, MaxPool\n",
    "        self.conv1 = tf.keras.layers.Conv2D(channel_1, (3, 3), activation='relu', padding='same', kernel_initializer=initializer)\n",
    "        self.mp1 = tf.keras.layers.MaxPooling2D((2, 2))\n",
    "\n",
    "        # Сверточный слой 2: 64 фильтра, MaxPool\n",
    "        self.conv2 = tf.keras.layers.Conv2D(channel_2, (3, 3), activation='relu', padding='same', kernel_initializer=initializer)\n",
    "        self.mp2 = tf.keras.layers.MaxPooling2D((2, 2))\n",
    "        self.d1 = tf.keras.layers.Dropout(0.25)\n",
    "\n",
    "        # Используем flatten для сглаживания и Dropout для того, чтобы избежать переобучения\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.fc1 = tf.keras.layers.Dense(num_classes_relu, activation='relu')\n",
    "        self.d2 = tf.keras.layers.Dropout(0.25)\n",
    "        self.fc2 = tf.keras.layers.Dense(num_classes_softmax, activation='softmax')\n",
    "\n",
    "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        ############################################################################\n",
    "        #                            END OF YOUR CODE                              #\n",
    "        ############################################################################\n",
    "    \n",
    "    def call(self, input_tensor, training=False):\n",
    "        ############################################################################\n",
    "        # TODO: Construct a model that performs well on CIFAR-10                   #\n",
    "        ############################################################################\n",
    "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "        x = self.conv1(input_tensor)\n",
    "        x = self.mp1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.mp2(x)\n",
    "        x = self.d1(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.d2(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        ############################################################################\n",
    "        #                            END OF YOUR CODE                              #\n",
    "        ############################################################################\n",
    "        return x\n",
    "\n",
    "\n",
    "print_every = 700\n",
    "num_epochs = 10\n",
    "\n",
    "model = CustomConvNet()\n",
    "\n",
    "def model_init_fn():\n",
    "    return CustomConvNet()\n",
    "\n",
    "def optimizer_init_fn():\n",
    "    learning_rate = 1e-3\n",
    "    return tf.keras.optimizers.Adam(learning_rate) \n",
    "\n",
    "train_part34(model_init_fn, optimizer_init_fn, num_epochs=num_epochs, is_training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "700/700 [==============================] - 14s 19ms/step - loss: 1.6647 - sparse_categorical_accuracy: 0.3961 - val_loss: 1.2259 - val_sparse_categorical_accuracy: 0.5720\n",
      "Epoch 2/10\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 1.2714 - sparse_categorical_accuracy: 0.5420 - val_loss: 1.0803 - val_sparse_categorical_accuracy: 0.6410\n",
      "Epoch 3/10\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 1.1270 - sparse_categorical_accuracy: 0.5973 - val_loss: 0.9909 - val_sparse_categorical_accuracy: 0.6600\n",
      "Epoch 4/10\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 1.0365 - sparse_categorical_accuracy: 0.6289 - val_loss: 0.9191 - val_sparse_categorical_accuracy: 0.6960\n",
      "Epoch 5/10\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.9773 - sparse_categorical_accuracy: 0.6522 - val_loss: 0.8889 - val_sparse_categorical_accuracy: 0.6880\n",
      "Epoch 6/10\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.9227 - sparse_categorical_accuracy: 0.6712 - val_loss: 0.8820 - val_sparse_categorical_accuracy: 0.6890\n",
      "Epoch 7/10\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.8761 - sparse_categorical_accuracy: 0.6871 - val_loss: 0.8150 - val_sparse_categorical_accuracy: 0.7250\n",
      "Epoch 8/10\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.8331 - sparse_categorical_accuracy: 0.7024 - val_loss: 0.8051 - val_sparse_categorical_accuracy: 0.7230\n",
      "Epoch 9/10\n",
      "700/700 [==============================] - 13s 19ms/step - loss: 0.7971 - sparse_categorical_accuracy: 0.7175 - val_loss: 0.7931 - val_sparse_categorical_accuracy: 0.7250\n",
      "Epoch 10/10\n",
      "700/700 [==============================] - 13s 18ms/step - loss: 0.7663 - sparse_categorical_accuracy: 0.7281 - val_loss: 0.8346 - val_sparse_categorical_accuracy: 0.7180\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.8476 - sparse_categorical_accuracy: 0.7132\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8475560545921326, 0.7131999731063843]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model_init_fn()\n",
    "model.compile(optimizer=optimizer_init_fn(),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=[tf.keras.metrics.sparse_categorical_accuracy])\n",
    "model.fit(X_train, y_train, batch_size=70, epochs=10, validation_data=(X_val, y_val))\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"custom_conv_net_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_12 (Conv2D)          multiple                  896       \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  multiple                  0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          multiple                  18496     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPoolin  multiple                  0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         multiple                  0         \n",
      "                                                                 \n",
      " flatten_12 (Flatten)        multiple                  0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            multiple                  409700    \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         multiple                  0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            multiple                  1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 430102 (1.64 MB)\n",
      "Trainable params: 430102 (1.64 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
